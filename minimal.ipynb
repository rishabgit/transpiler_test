{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL.Image\n",
    "import ivy\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Convolutional Neural Network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(26 * 26 * 10, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "        )\n",
    "        \n",
    "        self.apply(self.initialize_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def predict(self, inp):\n",
    "        \"\"\"predict digit for input\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            raw_output = self(inp)\n",
    "            _, pred = torch.max(raw_output, 1)\n",
    "            return pred\n",
    "        \n",
    "    def initialize_weights(self, module):\n",
    "        if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(\"0.png\")\n",
    "np_img = np.array(img)\n",
    "tensor_img = torch.from_numpy(np_img).float()\n",
    "tensor_img = tensor_img.unsqueeze(0).unsqueeze(0)\n",
    "tensor_img = torch.nn.functional.interpolate(tensor_img, size=28, mode='bicubic', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 16:11:39.617508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:root:To preserve the compiler and transpiler caches across multiple machines, ensure that the relative path of your projects from the .ivy folder is consistent across all machines. You can do this by adding .ivy to your home folder and placing all projects in the same place relative to the home folder on all machines.\n",
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/rishab/anaconda3/envs/ivy/lib/python3.10/site-packages/ivy/func_wrapper.py:242: UserWarning: Creating many views will lead to overhead when performing inplace updates with this backend\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "jax_graph = ivy.transpile(model, to=\"haiku\", args=(tensor_img,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishab/anaconda3/envs/ivy/lib/python3.10/site-packages/ivy/func_wrapper.py:242: UserWarning: Creating many views will lead to overhead when performing inplace updates with this backend\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "to_flax_module.<locals>.TranspiledFlaxModule.__init__() got an unexpected keyword argument 'lazy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jax_graph \u001b[39m=\u001b[39m ivy\u001b[39m.\u001b[39;49mtranspile(model, to\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mflax\u001b[39;49m\u001b[39m\"\u001b[39;49m, args\u001b[39m=\u001b[39;49m(tensor_img,))\n",
      "File \u001b[0;32m~/anaconda3/envs/ivy/lib/python3.10/site-packages/ivy/compiler/compiler.py:148\u001b[0m, in \u001b[0;36mtranspile\u001b[0;34m(source, to, with_numpy, args, kwargs, params_v, v, *objs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_compiler\u001b[39;00m \u001b[39mimport\u001b[39;00m transpile \u001b[39mas\u001b[39;00m _transpile\n\u001b[1;32m    123\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mTranspile Callable objects passed as arguments. If args and kwargs are specified,\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mtranspilation is performed eagerly, otherwise, transpilation will happen lazily.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mEither a transpiled Graph or a non-initialized LazyGraph.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m _transpile(\n\u001b[1;32m    149\u001b[0m     \u001b[39m*\u001b[39;49mobjs,\n\u001b[1;32m    150\u001b[0m     source\u001b[39m=\u001b[39;49msource,\n\u001b[1;32m    151\u001b[0m     to\u001b[39m=\u001b[39;49mto,\n\u001b[1;32m    152\u001b[0m     with_numpy\u001b[39m=\u001b[39;49mwith_numpy,\n\u001b[1;32m    153\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    154\u001b[0m     kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m    155\u001b[0m     params_v\u001b[39m=\u001b[39;49mparams_v,\n\u001b[1;32m    156\u001b[0m     v\u001b[39m=\u001b[39;49mv,\n\u001b[1;32m    157\u001b[0m )\n",
      "File \u001b[0;32mXXI.pyx:278\u001b[0m, in \u001b[0;36mXXI.transpile\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mVXI.pyx:442\u001b[0m, in \u001b[0;36mVXI._transpile_trainable_module\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mVXI.pyx:213\u001b[0m, in \u001b[0;36mVXI.to_flax_module\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: to_flax_module.<locals>.TranspiledFlaxModule.__init__() got an unexpected keyword argument 'lazy'"
     ]
    }
   ],
   "source": [
    "jax_graph = ivy.transpile(model, to=\"flax\", args=(tensor_img,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
